import os
cache_path = "Z:\\Development Projects\\huggingface"  # Modify as needed
os.environ["TRANSFORMERS_CACHE"] = cache_path
os.environ["HF_HUB_CACHE"] = cache_path
os.environ["HF_HOME"] = cache_path
import sys

import numpy as np
from PIL import Image

import torch
from diffusers import (
    ControlNetModel,
    StableDiffusionXLControlNetPipeline
)
from huggingface_hub import login, hf_hub_download
from controlnet_aux import AnylineDetector  # used for edge detection
from pydantic import BaseModel

# Replace with your actual token if needed
login(token="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")

# ------------------------------------------------------------------------------
# Edge Detection
# ------------------------------------------------------------------------------
def generate_edges(input_image: Image.Image) -> Image.Image:
    """
    Given an input PIL image, returns an edge map generated by the AnylineDetector.
    If the output is a NumPy array, it is converted to a PIL Image.
    """
    img_processor = AnylineDetector.from_pretrained(
        "TheMistoAI/MistoLine",
        filename="MTEED.pth",
        subfolder="Anyline"
    )
    edge_result = img_processor(input_image)
    if isinstance(edge_result, np.ndarray):
        edge_result = Image.fromarray(edge_result)
    return edge_result

# ------------------------------------------------------------------------------
# Configuration Model
# ------------------------------------------------------------------------------
class Item(BaseModel):
    prompt: str = "a stunning view of a cluster of modular pavilions nestled within the lush Brazilian jungle, the roof is built using woven bamboo elements, surrounded by majestic mountains rising in the background and a serene river flowing in the foreground, the trees are way taller than the pavilions, earthy tones that blend harmoniously with the yellowish greens of the surrounding jungle, volumetric sunlight goes across the jungle, creating fascinating light rays, 4k, high resolution, realistic render, architectural visualization"
    negative_prompt: str = "ugly, low quality"
    guidance_scale: float = 5.0
    control_strength: float = 0.5  # passed as controlnet_conditioning_scale
    input_image: str = "assets/readme_images/test.jpg"  # Path to the input image

# ------------------------------------------------------------------------------
# Main Execution
# ------------------------------------------------------------------------------
def main():
    # Create a configuration instance
    config = Item()

    if not config.input_image:
        print("Error: No input image path provided in the configuration (input_image).")
        sys.exit(1)

    # Load the input image
    try:
        input_img = Image.open(config.input_image).convert("RGB")
    except Exception as exc:
        print(f"Error loading image from '{config.input_image}': {exc}")
        sys.exit(1)

    # Generate edge map from the input image
    print("Generating edge map from input image...")
    edge_map = generate_edges(input_img)
    edge_map.save("edge_map.png")
    # edge_map.show()  # Uncomment if you want to visually inspect the edges

    # Set up generator for reproducibility (using a fixed seed for simplicity)
    generator = torch.Generator("cuda").manual_seed(100)

    # ----------------------------------------------------------------------------
    # Model IDs and LoRA Weights
    # ----------------------------------------------------------------------------
    # Ensure that your base model is indeed an SDXL model if you're using an SDXL ControlNet.
    base_model_id = "SG161222/RealVisXL_V4.0"  
    controlnet_model_id = "diffusers/controlnet-canny-sdxl-1.0"

    # Optional LoRA details 
    repo_name = "ByteDance/Hyper-SD"
    ckpt_name = "Hyper-SDXL-8steps-lora.safetensors"

    # ----------------------------------------------------------------------------
    # Load ControlNet Model
    # ----------------------------------------------------------------------------
    print("Loading ControlNet model for edge conditioning...")
    controlnet = ControlNetModel.from_pretrained(
        controlnet_model_id,
        torch_dtype=torch.float16,
        cache_dir=cache_path
    )

    # ----------------------------------------------------------------------------
    # Load the SDXL ControlNet Pipeline
    # ----------------------------------------------------------------------------
    print("Loading diffusion pipeline with ControlNet...")
    pipe = StableDiffusionXLControlNetPipeline.from_pretrained(
        base_model_id,
        controlnet=controlnet,
        torch_dtype=torch.float16,
        cache_dir=cache_path
    )


    # ----------------------------------------------------------------------------
    # Load and Fuse LoRA Weights
    # ----------------------------------------------------------------------------
    try:
        print("Loading and fusing LoRA weights...")
        lora_path = hf_hub_download(repo_name, ckpt_name)
        pipe.load_lora_weights(lora_path)
        pipe.fuse_lora(lora_scale=0.125)
    except Exception as exc:
        print("Skipping LoRA since no valid weights or an error occurred:", exc)

    # ----------------------------------------------------------------------------
    # Device Setup
    # ----------------------------------------------------------------------------
    pipe.to("cuda")
    pipe.enable_model_cpu_offload()
    # Or optionally: pipe.enable_xformers_memory_efficient_attention()

    # ----------------------------------------------------------------------------
    # Generate Image with ControlNet
    # ----------------------------------------------------------------------------
    print("Generating image with ControlNet conditioning...")

    result = pipe(
        prompt=config.prompt,
        negative_prompt=config.negative_prompt,
        guidance_scale=config.guidance_scale,
        controlnet_conditioning_scale=config.control_strength,
        generator=generator,
        num_inference_steps=12,
        image=edge_map
    )

    generated_image = result.images[0]
    output_path = "assets/output/sdxl-2-2-3-hyper.png"
    generated_image.save(output_path)

    print(f"Image generated and saved to {output_path}")

if __name__ == "__main__":
    main()